{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fc2c824-0241-4005-9d57-77a58f9b20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import faiss\n",
    "import re\n",
    "\n",
    "# Step 1: Extract data from PDF\n",
    "def extract_text_with_headings(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    data = []\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            if re.match(r\"^[A-Z][A-Z\\s]+$\", line.strip()):  # Heading (uppercase assumption)\n",
    "                data.append({\"heading\": line.strip(), \"content\": \"\"})\n",
    "            elif data:\n",
    "                data[-1][\"content\"] += line.strip() + \" \"\n",
    "    return data\n",
    "\n",
    "# Step 2: Process text into meaningful chunks\n",
    "def chunk_by_headings(data, max_chunk_size=500):\n",
    "    chunks = []\n",
    "    for section in data:\n",
    "        heading = section[\"heading\"]\n",
    "        content = section[\"content\"]\n",
    "        words = content.split()\n",
    "        for i in range(0, len(words), max_chunk_size):\n",
    "            chunk = \" \".join(words[i:i + max_chunk_size])\n",
    "            chunks.append(f\"{heading}\\n{chunk}\")\n",
    "    return chunks\n",
    "\n",
    "# Step 3: Embed and store the data\n",
    "def store_in_faiss_advanced(chunks, faiss_index_path=\"faiss_index\"):\n",
    "    model= SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(chunks, normalize_embeddings=True)  # Normalize embeddings\n",
    "\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)  # Inner product for normalized vectors\n",
    "    index.add(np.array(embeddings))\n",
    "\n",
    "    faiss.write_index(index, faiss_index_path)\n",
    "    return faiss_index_path, chunks\n",
    "\n",
    "def re_rank_results(chunks, query, top_k=3):\n",
    "    model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "    query_embedding = model.encode([query], normalize_embeddings=True)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    embeddings = model.encode(chunks, normalize_embeddings=True)\n",
    "    similarities = cosine_similarity(query_embedding, embeddings)[0]\n",
    "    \n",
    "    # Rank and retrieve top-k\n",
    "    ranked_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    return [chunks[i] for i in ranked_indices], similarities[ranked_indices]\n",
    "    \n",
    "def query_faiss_with_reranking(index, query, chunks, top_k=5):\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    query_embedding = model.encode([query], normalize_embeddings=True)\n",
    "    distances, indices = index.search(np.array(query_embedding), top_k)\n",
    "\n",
    "    retrieved_chunks = [chunks[i] for i in indices[0]]\n",
    "    reranked_chunks, reranked_scores = re_rank_results(retrieved_chunks, query, top_k=3)\n",
    "    return reranked_chunks\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b60039b3-8573-41b1-9fdd-9fbe94a78d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your question:  Tell me about david goggins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context provided for this query is:  ABOUT THE AUTHOR\n",
      "DAVID GOGGINS is a retired Navy SEAL and the only member of the U.S. Armed Forces ever to complete SEAL training, U.S. Army Ranger School, and Air Force Tactic al Air Controller training. Goggins has competed in more than sixty ultra-marathons , triathl ons, and ultra- triathlons , setting new course records and regularly placing in the top five. A forme r Guinness World Record holder for completing 4,030 pull-ups in seventeen hours, he’s a much -sought -after public speaker who’ s shared his story with the staffs of Fortune 500 companies , professional sports teams, and hundreds of thousands of students across the country . OceanofPDF .com\n",
      "CHAPTER FIVE\n",
      "carry their boat and log by themselves. He admitted he was fighting his own demons on that beach. That his foundation was cracked. “I was an insecure person with low self esteem trying to grind an axe,” he said, “and my own ego, arrogance, and insecurity made my own life more difficult.” Translation: his mind broke down in ways he’d never experienced before or since. On Mon day afternoon we did a bay swim, and when he emer ged from the water , he was hurting. Watchin g him it was obvious he could barely walk and that his mind was teetering on the brink. We locked eyes and I saw that he was asking himself those simple questions and couldn’ t find an answer . He looked a lot like I did when I was in Pararescue, searching for a way out. From then on Dobbs was one of the worst performers on the whole beach, and that fucked him up bad. “All the people I’d categorized as lower than worms were kicking my butt,” he said. Soon his crew was down to two men, and he got moved to another boat crew with taller guys. When they lifted the boat head high, he wasn’ t even able to reach that motherfucker , and all of his insecurities about his size and his past started caving in on him. “I started to believe that I didn’ t belong there,” he said. “That I was genetically inferior . It was like I had superpowers, and I’d lost them. I was in a place in my mind I’d never been, and I didn’ t have a road map.” Think about where he was at that time. This man had excelled through the first few weeks of BUD/S. He’d come from nothing and was a phenomenal athlete. He had so many experiences along the way he could have leaned on. He’d calloused his mind plenty , but because his foundation was cracked, when shit got real he lost control of his mindset and became a slave to his self doubt. On Mon day night, Dobbs reported to medical complaining about his feet. He was sure he had stress fractures, but when he took off his boots they weren’ t swollen or black and blue like he’d imagined. They looked perfectly healthy . I know that because I was at med check too, sitting right besid e him. I saw his blank stare and knew the inevitable was near. It was the look that comes over a man’ s face after he surrenders his soul. I had the same look in my eyes when I quit Pararescue. What will forever bond me and Shawn Dobbs is the fact that I knew he was going to quit before he did. The docs offered him Motrin and sent him back into the suffering. I remember watching Shawn lace his boots, wondering at what point he would finally break. That’s when SBG pulled up in his\n",
      "CHAPTER SEVEN\n",
      "upright. He was about to lap me, three miles from the finish line, on pace for a course record, twenty -two hours and sixte en minutes, but what I remember most is how graceful he looked running at an incredible 6:30 per mile pace. He was levitating over the mud, riding a whole dif ferent Zen. His feet barely touched the ground, and it was a beautiful fucking sight. The Speedgoat was the living, breathing answer to the question that colonized my mind after the Las Vegas marathon. What am I capable of? Watching that bad man glide across the most challenging terrain made me realize that there is a whole other level of athlete out there in the world, and that some of that was inside me too. In fact, it’s in all of us. I’m not saying that genetics don’t play a role in athletic performance, or that everyone has an undiscovered ability to run a four-minute mile, dunk like LeBron James, shoot like Steph Curry , or run the Hurt 100 in twenty -two hours. We don’t all have the same floor or ceiling, but we each have a lot more in us than we know , and when it comes to endurance sports like ultra runnin g, everyone can achieve feats they once thought impossible. In order to do that we must change our mind s, be willing to scrap our identity , and make the extra effort to always find more in order to become more. We must remove our governor . That day on the Hurt 100 circui t, after seeing Meltzer run like a superhero, I finished my fourth lap in all kinds of pain and took time to watch him celebrate, surrou nded by his team. He’d just achieved something nobody had ever done before and here I was with another full lap to go. My legs were rubber , my feet swollen. I did not want to go on, but I also knew that was my pain talking. My true potential was still undetermined. Looking back, I’d say I’d given 60 percent, which meant my tank was just shy of half-full. I’d like to sit here and tell you I went all-out and drained that fucker on lap five, but I was still a mere tourist on planet ultra. I wasn’ t the master of my mind. I was in the laboratory , still in discovery mode, and I walked every single step of my fifth and final lap. It took me eight hours, but the rain had stopped, the tropical glow of the warm Hawaiian sun felt phenomenal, and I got the job done. I finished Hurt 100 in thirty -three hours and twenty -three minutes, just shy of the thirty -six-hour cut off, good enough for ninth place. Only twenty -three athletes finished the entire race, and I was one of them. I was so thrashed afterward, two people carried me to the car, and Kate had to spin\n",
      "\n",
      " Answer: David Goggins is a retired Navy SEAL and the only member of the U.S. Armed Forces ever to complete SEAL training, U.S. Army Ranger School, and Air Force Tactical Air Controller training. He has participated in more than sixty ultra-marathons, triathlons, and ultra-triathlons, setting new course records and regularly placing in the top five. Goggins is also a former Guinness World Record holder for completing 4,030 pull-ups in seventeen hours. He is a sought-after public speaker who has shared his story with Fortune 500 companies, professional sports teams, and students across the country. Goggins is known for his mental toughness and perseverance in the face of challenges and setbacks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Use OpenAI GPT for generating answers\n",
    "def get_answer_with_openai(context, query, openai_api_key):\n",
    "    print(\"Context provided for this query is: \", context)\n",
    "    client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "\n",
    "    # Construct the conversation messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context only.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"}\n",
    "    ]\n",
    "\n",
    "    # Call OpenAI Chat Completion API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-3.5-turbo\" for a faster, cheaper model\n",
    "        messages=messages,\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    # Extract and return the assistant's reply\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    pdf_path = \"cant_hurt_me.pdf\"\n",
    "    openai_api_key = \"Open-ai-Key\"\n",
    "\n",
    "    # Step 1: Extract and store data\n",
    "    data = extract_text_with_headings(pdf_path)\n",
    "    chunks = chunk_by_headings(data)\n",
    "    faiss_index_path, formatted_chunks = store_in_faiss_advanced(chunks)\n",
    "\n",
    "    # Step 2: Load FAISS and query\n",
    "    index = faiss.read_index(faiss_index_path)\n",
    "    user_query = input(\"Enter your question: \")\n",
    "    relevant_chunks = query_faiss_with_reranking(index, user_query, formatted_chunks)\n",
    "\n",
    "    # Step 3: Use OpenAI to get the answer\n",
    "    context = \"\\n\".join(relevant_chunks)\n",
    "    answer = get_answer_with_openai(context, user_query, openai_api_key)\n",
    "\n",
    "    print(f\"\\n Answer: {answer}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b8014-6cab-48d4-879c-33039968e57e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6487522a-6737-4973-bb54-ba23a0e59fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytesseract) (24.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytesseract) (11.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d6c863-016e-4a8d-a1a4-8607ab5e0596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "Error during OCR: tesseract is not installed or it's not in your PATH. See README file for more information.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Path to Tesseract executable (only needed on Windows, update as per your installation)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def perform_ocr(image_path):\n",
    "    \"\"\"\n",
    "    Perform OCR on the given image file.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted text from the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Perform OCR\n",
    "        extracted_text = pytesseract.image_to_string(image)\n",
    "\n",
    "        return extracted_text\n",
    "    except Exception as e:\n",
    "        return f\"Error during OCR: {e}\"\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"/Users/Aman-India/Desktop/personal/temp.png\"  # Replace with your image file path\n",
    "    text = perform_ocr(image_path)\n",
    "    print(\"Extracted Text:\")\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254dba71-9870-4a11-9ecd-d42fd64cb448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
